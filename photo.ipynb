{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from window import window\n",
    "from cv2 import imread, imwrite\n",
    "\n",
    "# Imports for Neural Network\n",
    "from ml.photo.optimize import optimize\n",
    "from ml.photo.evaluate import ffwd, ffwd_to_img, ffwd_different_dimensions\n",
    "from ml.photo.utils import isimage\n",
    "from tensorflow.logging import set_verbosity, ERROR, DEBUG\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "set_verbosity(DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Move to file\n",
    "class Photo:\n",
    "    def __init__(self):\n",
    "        self.dataSetDir = 'D:\\ML\\datasets\\COCO2014'\n",
    "        self.imageDir = 'photo\\style{}'\n",
    "        self.styleDir = 'photo\\style{}.jpg'\n",
    "        self.examplePaths = ['photo\\example{}.jpg'.format(i) for i in range(3)]\n",
    "        self.modelDir = 'D:\\ML\\models\\smart_paint\\style{}'\n",
    "        self.vggPath = 'D:\\ML\\models\\imagenet-vgg-verydeep-19.mat'\n",
    "\n",
    "        self.batch = 22\n",
    "        self.epochs = 15\n",
    "        self.device = '/gpu:1'\n",
    "        self.learningRate = 0.001\n",
    "        self.contentWeight = 7.5\n",
    "        self.styleWeight = 200\n",
    "        self.tvWeight = 200\n",
    "        self.checkIterations = 500\n",
    "\n",
    "    def train(self, styleCount):\n",
    "        modelDir = self.modelDir.format(styleCount)\n",
    "        imagesDir = self.imageDir.format(styleCount)\n",
    "        imwrite(imagesDir + '/c{}_s{}_tv{}.jpg'.format(self.contentWeight,  self.styleWeight, self.tvWeight), style)\n",
    "        \n",
    "        print('Training {} has been began\\n'.format(styleCount))\n",
    "        \n",
    "        for preds, losses, iteration, epoch in optimize(self.dataSetDir, style, self.epochs, self.batch,\n",
    "                                                    self.contentWeight, self.styleWeight, self.tvWeight,\n",
    "                                                    self.vggPath, modelDir, modelDir + \"/e0_i4137/model.ckpt\", self.checkIterations, \n",
    "                                                    self.learningRate, self.device):\n",
    "            styleLoss, contentLoss, tvLoss, loss = losses\n",
    "            print('\\nEpoch %d, Iteration: %d, Loss: %s' % (epoch, iteration, loss))\n",
    "            print('Style: %s, Content:%s, Tv: %s\\n' % (styleLoss, contentLoss, tvLoss))\n",
    "            \n",
    "            files = [imagesDir + '/e{}_i{}-{}.jpg'.format(epoch, iteration, image) for image in range(len(self.examplePaths))]\n",
    "            ffwd_different_dimensions(self.examplePaths, files, modelDir + '/e{}_i{}'.format(epoch, iteration), '/gpu:0')\n",
    "            \n",
    "        print('\\nTraining {} has been completed\\n\\n\\n'.format(styleCount))\n",
    "\n",
    "    def work(self, imagePath, styleID): # TODO: me\n",
    "        checkpointPath = self.modelDir + '/style%s' % styleID  + '/e0_i3761/model.ckpt'\n",
    "        if type(imagePath) is str:\n",
    "          imagePath = [imagePath]\n",
    "        return ffwd(imagePath, 'example.jpg', checkpointPath, self.device, self.batch)\n",
    "      \n",
    "    def autowork(self, style):\n",
    "      files = ['example{}.jpg'.format(image) for image in range(len(self.examplePaths))]\n",
    "      ffwd_different_dimensions(self.examplePaths, files, self.modelsDir + '/style%s/model.ckpt' % style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializate vatiables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo = Photo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(30000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 30 seconds\n",
      "Training 6 has been began\n",
      "\n",
      "Train set has been trimmed slightly..\n",
      "WARNING:tensorflow:From C:\\Users\\ml-server\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\ml-server\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%autosave 30\n",
    "photo.train(6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}